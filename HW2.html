

<html>
    <head>
    <title> CS585 Homework Template: HW[x] Student Name [xxx]  </title>
    <style>
    <!--
    body{
    font-family: 'Trebuchet MS', Verdana;
    }
    p{
    font-family: 'Trebuchet MS', Times;
    margin: 10px 10px 15px 20px;
    }
    h3{
    margin: 5px;
    }
    h2{
    margin: 10px;
    }
    h1{
    margin: 10px 0px 0px 20px;
    }
    div.main-body{
    align:center;
    margin: 30px;
    }
    hr{
    margin:20px 0px 20px 0px;
    }
    -->
    </style>
    </head>
    
    <body>
    <center>
    <a href="http://www.bu.edu"><img border="0" src="http://www.cs.bu.edu/fac/betke/images/bu-logo.gif"
    width="119" height="120"></a>
    </center>
    
    <h1>Assignment Title</h1>
    <p> 
     CS 585 HW 2 <br>
     Zhou Nan <br>
    
        Spring 2021
    </p>
    
    <div class="main-body">
    <hr>
    <h2> Problem Definition </h2>
    <p>
        Design and implement algorithms that recognize hand shapes (such as making a fist, thumbs up, thumbs down, pointing with an index finger etc.) or gestures (such as waving with one or both hands, swinging, drawing something in the air etc.) and create a graphical display that responds to the recognition of the hand shapes or gestures.
    </p>
    
    <hr>
    <h2> Method and Implementation </h2>
    <p>
    </p>
    
    <p>
    
    This analysis can be used for a live camera or a video file. When the camera is open or a video file is loaded, each frame goes through the algorithm as a single still image and the analysis is carried out from then. 
    The first step is to capture the background by pressing 'c' on the keyboard and remove it from the future frame. On the top right corner of the display window, there is a green rectangle drawn for the hand position.
    Hand gesture is captured in this region. This region is cropped from the image and goes through further analysis. 
    The first step is to convert the cropped color-image to gray scale then blur the image. It is converted to binary image using thresholding.
    In order to capture the hand position well, the method of finding the contour with the largest area is used. And then find the number of convex of it to detect the hand shapes. 

    </p>
    
    <hr>
    <h2>Experiments</h2>
    <p>
     
    Camera of the laptop is used to have the live stream and result of each step is recorded. When the camera is on, the region of hand is cropped from the image.
    Then, hand is distinguished from the background and convert to binary image. Lastly, the contour of the hand shape is drawn. 
    The followings are the hand-shape detection examples of 'Paper', 'Scissor' and 'Stone' respectively.
    </p>
 

    <p>
    <table>
    <tr><td colspan=3><center><h3>Process</h3></center></td></tr>
    <tr>
        <td> Image-Cropped </td><td> Hand-Filtered</td> <td> Image-Binary </td> <td> Image-Contour</td> 
    </tr>
    <tr>
        <td> <img width="200px" src="paper1.png"> </td>
        <td> <img width="200px" src="paper2.png"> </td>
        <td> <img width="200px" src="paper3.png"> </td>
        <td> <img width="200px" src="paper4.png"> </td>
    </tr> 

    <tr>
      
      <td> <img width="200px" src="scissor1.png"> </td>
        <td> <img width="200px" src="scissor2.png"> </td>
        <td> <img width="200px" src="scissor3.png"> </td>
        <td> <img width="200px" src="scissor4.png"> </td>
    </tr> 
    <tr>
      
      <td> <img width="200px" src="stone1.png"> </td>
        <td> <img width="200px" src="stone2.png"> </td>
        <td> <img width="200px" src="stone3.png"> </td>
        <td> <img width="200px" src="stone4.png"> </td>
    </tr> 
    </table>
    </p>


    
    <hr>
    <h2> Results</h2>
    <p>
    Hand shapes are captured correctly for live camera. And below is a recorded test video. Here are the screenshots of the hand-shape detection while the video is played.

    <br>
     <video width="320" height="240" autoplay muted>
     <source src="vid.mov" type="video/mp4">
     Your browser does not support the video tag.
    </video>





    </p>
    
    <p>
    <table>
    <tr><td colspan=3><center><h3>Results</h3></center></td></tr>
    <tr>
    <td> Paper </td><td> Scissor</td> <td> Stone</td> 
    </tr>
    <tr>
        <td> <img width="300px" src="res1.png"> </td>
        <td> <img width="300px" src="res2.png"> </td>
        <td> <img width="300px" src="res3.png"> </td>
    </tr> 
    </table>
    </p>
    
    
    
    <hr>
    <h2> Discussion </h2>
    
    <p> 
    Discuss your method and results:
    <ul>
    <li>The algorithm is able to detect hand shapes of 'paper', 'scissor', 'stone', 'three' and 'four' correctly. </li>
    <li>However, while extracting hand from the background, it is largely affected by the background color and light. The larger difference between background color and skin-color, the better the extraction is.</li>
    <li>More templates could be used to detect the hand shapes using template-matching method since these hand shapes vary based on people.</li> 
    </ul>
    </p>
    
    <hr>
    <h2> Conclusions </h2>
    
    <p>
    Through this system, selected hand shapes can be recognised from both live camera and video files. Each frame of the video is analysed as a static image, which goes through the recognition process.
    </p>
    
    
    <hr>
    <h2> Credits and Bibliography </h2>
    <p>
    
    <p>
    This is an individual work. 
    </p>
    <hr>
    </div>
    </body>
    
    
    
    </html>
    